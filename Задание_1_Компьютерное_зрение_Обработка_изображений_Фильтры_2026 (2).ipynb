{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":549,"status":"ok","timestamp":1772028427825,"user":{"displayName":"Леонид Байдаров","userId":"10961009866938662820"},"user_tz":-300},"id":"z_-gZ-4o5uGm"},"outputs":[],"source":["from scipy import ndimage\n","import matplotlib.pyplot as plt\n","import imageio\n","import PIL\n","import numpy as np\n","import cv2\n","import skimage"]},{"cell_type":"markdown","metadata":{"id":"DwigyasxyI2k"},"source":["Задание на практику.\n","\n","1. Изучить блокнот.\n","1. Повторить на других изображениях.\n","1. Найти еще не менее 3х фильтров, которые применяются для работы с изображениями.\n","1. Применить найденные фильтры."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27500,"status":"ok","timestamp":1772028455357,"user":{"displayName":"Леонид Байдаров","userId":"10961009866938662820"},"user_tz":-300},"id":"OtoZkkcy57i7","outputId":"2e522bb3-81be-4727-cd0f-4ac4dfefe9b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"h0l1TaKT5uGn"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n","Requirement already satisfied: numpy\u003c2.6,\u003e=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy) (2.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n","Requirement already satisfied: kiwisolver\u003e=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: numpy\u003e=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0)\n","Requirement already satisfied: pillow\u003e=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib) (1.17.0)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (2.37.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from imageio) (2.0.2)\n","Requirement already satisfied: pillow\u003e=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio) (11.3.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n","Requirement already satisfied: numpy\u003e=1.24 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.0.2)\n","Requirement already satisfied: scipy\u003e=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.3)\n","Requirement already satisfied: networkx\u003e=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.6.1)\n","Requirement already satisfied: pillow\u003e=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n","Requirement already satisfied: imageio!=2.35.0,\u003e=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.2)\n","Requirement already satisfied: tifffile\u003e=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2026.2.16)\n","Requirement already satisfied: packaging\u003e=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (26.0)\n","Requirement already satisfied: lazy-loader\u003e=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.13.0.92)\n","Requirement already satisfied: numpy\u003e=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: numpy\u003e=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy\u003e=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: joblib\u003e=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n","Requirement already satisfied: threadpoolctl\u003e=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n","Requirement already satisfied: absl-py\u003e=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers\u003e=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.12.19)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,\u003e=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n","Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang\u003e=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (26.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.6)\n","Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six\u003e=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: typing-extensions\u003e=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n","Requirement already satisfied: wrapt\u003e=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.1.1)\n","Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.78.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n","Requirement already satisfied: keras\u003e=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: numpy\u003c2.2.0,\u003e=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py\u003e=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n","Requirement already satisfied: ml-dtypes\u003c1.0.0,\u003e=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow) (0.46.3)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (0.18.0)\n","Requirement already satisfied: charset_normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.12/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow) (3.4.4)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.12/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow) (3.11)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow) (2.5.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorflow) (2026.1.4)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0-\u003etensorflow) (3.10.2)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0-\u003etensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0-\u003etensorflow) (3.1.5)\n","Requirement already satisfied: markupsafe\u003e=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard~=2.19.0-\u003etensorflow) (3.0.3)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (4.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (0.1.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.25.0+cpu)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: torch==2.10.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.10.0+cpu)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.10.0-\u003etorchvision) (3.24.2)\n","Requirement already satisfied: typing-extensions\u003e=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.10.0-\u003etorchvision) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.10.0-\u003etorchvision) (75.2.0)\n","Requirement already satisfied: sympy\u003e=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.10.0-\u003etorchvision) (1.14.0)\n","Requirement already satisfied: networkx\u003e=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.10.0-\u003etorchvision) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.10.0-\u003etorchvision) (3.1.6)\n","Requirement already satisfied: fsspec\u003e=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.10.0-\u003etorchvision) (2025.3.0)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy\u003e=1.13.3-\u003etorch==2.10.0-\u003etorchvision) (1.3.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2-\u003etorch==2.10.0-\u003etorchvision) (3.0.3)\n"]}],"source":["!pip install scipy\n","!pip install  matplotlib\n","!pip install  imageio\n","!pip install  pillow\n","!pip install  numpy\n","!pip install  scikit-image\n","!pip install opencv-python\n","!pip install scikit-learn\n","!pip install tensorflow\n","!pip install torchvision\n"]},{"cell_type":"markdown","metadata":{"id":"4zzw3eqp8d2L"},"source":["# Библиотека OpenCV и работа с изображениями\n","\n","Ссылка на документацию:\n","https://docs.opencv.org/4.10.0/d9/df8/tutorial_root.html\n","\n","## Инициализация\n","\n","Сегодня мы работаем с изображениями. Давайте загрузим несколько. Вы можете загрузить изображения с помощью команды Unix/Windows curl. После загрузки изображения находятся в локальной файловой системе.\n","\n","Источники изображений:\n","\n","Place Kitten — Конечно, мы будем использовать изображения кошек! Мы используем базовый URL Place Kitten, за которым следуют ширина и высота, разделенные обратными косыми чертами ''/''. Например, используйте URL https://placekitten.com/500/300, чтобы получить изображение кошки шириной 500 пикселей и высотой 300 пикселей.\n","\n","Ну и еще изображение Ван Гога из wikimedia в приличном разрешении.\n","\n","\n","Вы можете использовать любое другое изображение, если хотите.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fcmafOB6Tsqi"},"outputs":[{"name":"stdout","output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100    15  100    15    0     0     32      0 --:--:-- --:--:-- --:--:--    32\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  2144  100  2144    0     0   9335      0 --:--:-- --:--:-- --:--:--  9362\n"]}],"source":["!curl -o \"cat.jpg\" \"https://placekitten.com/500/300\"\n","\n","!curl -o \"gogh.jpg\" \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Vincent_van_Gogh_-_National_Gallery_of_Art.JPG/367px-Vincent_van_Gogh_-_National_Gallery_of_Art.JPG\""]},{"cell_type":"markdown","metadata":{"id":"bGU2P8ChUUjq"},"source":["## OpenCV\n","\n","OpenCV — чрезвычайно популярная библиотека компьютерного зрения, написанная на C++, с множеством мощных инструментов для CV. Она позволяет читать, записывать и показывать изображения и видео, читать потоки веб-камеры, находить совпадающие ключевые точки между двумя изображениями и многое другое.\n","\n","OpenCV написана на C++, однако есть библиотека Python, которая использует эти оптимизированные библиотеки C++ и предоставляет API с использованием массивов numpy!\n","\n","Давайте импортируем OpenCV"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ri5xCiZbTst5"},"outputs":[],"source":["import cv2"]},{"cell_type":"markdown","metadata":{"id":"sNeTk6E9UbZL"},"source":["Чтение файла:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"W6nsSdJ-Ts10"},"outputs":[],"source":["image = cv2.imread(\"мальчик.jpg\")"]},{"cell_type":"markdown","metadata":{"id":"bVbFzFTLUlIm"},"source":["Изображения - это тензор!\n","PS все, вообще все - или тензор или вектор."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IKHBUaefUkMf"},"outputs":[{"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'shape'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2218740699.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"]}],"source":["type(image), image.shape, image.dtype"]},{"cell_type":"markdown","metadata":{"id":"mB54Tb-uU5hn"},"source":["## Каналы и форматы изображений\n","Форма цветного изображения — это (высота, ширина, цвета BGR)\n","Хотя может показаться странным, что высота идет первой, это потому, что OpenCV обрабатывает изображения как «строки» и «столбцы» изображения. «Высота» изображения — это количество строк!\n","\n","Цветные изображения состоят из «каналов» — каждый цвет, который мы можем отобразить, представляет собой некоторую комбинацию красного, зеленого и синего (ИЛИ, в случае изображения в оттенках серого, серого)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0bs8CGQSTs63"},"outputs":[],"source":["image.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MXYvarMSVh2b"},"outputs":[],"source":["image[0,0] # Получить значение пикселя, размещенного в точке (0,0) от верхнего левого угла"]},{"cell_type":"markdown","metadata":{"id":"ez91dhd0V6Jv"},"source":["## Отображение изображения\n","\n","Если вы используете скриптовый Python (не Jupyter notebook), команда imshow отобразит изображение. Однако это может вызвать проблемы в Jupyter notebooks.\n","\n","В Colab вы можете использовать следующую функцию в качестве замены:\n","from google.colab.patches import cv2_imshow\n","\n","На моей машине, однако, я также могу отображать изображения с помощью imshow (код ниже). Это остановит выполнение блокнота, пока вы не закроете окно с изображением."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NteFeEyXWQIM"},"outputs":[],"source":["# cv2.imshow('test', image)  #это работает на локальной машине\n","\n","if 'google.colab' in str(get_ipython()):\n","  print('Running on CoLab')\n","  from google.colab.patches import cv2_imshow\n","else:\n","  print('Not running on CoLab')\n","  def cv2_imshow(img):\n","      cv2.imshow('image', img)\n","      cv2.waitKey(0)\n","      cv2.destroyAllWindows()\n","\n","\n","cv2_imshow(image)"]},{"cell_type":"markdown","metadata":{"id":"ULy4145nWdb6"},"source":["## Каналы изображений\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2soI1Xr-Wliq"},"outputs":[],"source":["c1, c2, c3 = image[:,:,0], image[:,:,1], image[:,:,2]\n","\n","# отображаем\n","cv2_imshow(c1)\n","cv2_imshow(c2)\n","cv2_imshow(c3)\n","\n","# или все в одну строку\n","cv2_imshow( np.concatenate((c1,c2,c3), axis=1) )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1X3mjcV7W8WZ"},"outputs":[],"source":["empty_arr = np.zeros(c2.shape, dtype=np.uint8)\n","\n","# Складываем каналы, получаем новый 3 канал\n","manipulated_image = np.stack([ c1, empty_arr, c3, ], axis=2)\n","print(\"Created image of shape\",manipulated_image.shape)\n","cv2_imshow(manipulated_image)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"c3nRaRXlYPEK"},"outputs":[],"source":["import os\n","# сохраняем изображение\n","\n","output_path = os.path.join(\"output.png\")\n","cv2.imwrite(output_path, manipulated_image)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uU9ikLYUYegL"},"outputs":[],"source":["# читаем напрямую из файла\n","\n","test_read_output = cv2.imread(output_path)\n","print(\"Read file of shape:\",test_read_output.shape, \"type\",test_read_output.dtype)\n","cv2_imshow(test_read_output)"]},{"cell_type":"markdown","metadata":{"id":"QyGn1HezYyCv"},"source":["##Отображение с Matplotlib\n","\n","Кроме того, мы можем построить изображение с помощью matplotlib. Это очень полезно, если вы хотите рисовать поверх изображений. OpenCV предоставляет базовые функции, но Matplotlib намного лучше (например, пунктирные линии невозможны с OpenCV).\n","\n","Поскольку изображения представляют собой массив numpy, это должно быть просто, не так ли?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YcFRrGQiYqiR"},"outputs":[],"source":["plt.imshow(image)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"8nRS9aMuY8_o"},"source":["Цвета не те! Что происходит?\n","\n","По умолчанию цветные изображения открываются OpenCV как BGR, то есть значения для данного пикселя упорядочены «синий, зеленый, красный».\n","\n","Мы можем использовать функцию cv2.cvtColor, чтобы изменить цветовую систему нашего изображения."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sXvvrCf-ZDVn"},"outputs":[],"source":["image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","plt.imshow(image_rgb)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"DLtFlOrXZNes"},"source":["Matplotlib предполагает, что изображения находятся в формате RGB. OpenCV предполагает, что изображения находятся в формате BGR. Поэтому мы преобразуем цвета перед показом изображения. Вот функция для показа изображений OpenCV с помощью matplotlib."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Pyak9GjFZOz_"},"outputs":[],"source":["def imshow(image, *args, **kwargs):\n","    if len(image.shape) == 3:\n","      # Height, width, channels\n","      # Assume BGR, do a conversion\n","      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    else:\n","      # Height, width - must be grayscale\n","      # convert to RGB, since matplotlib will plot in a weird colormap (instead of black = 0, white = 1)\n","      image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n","    # Отрисовываем\n","    plt.imshow(image, *args, **kwargs)\n","    # Мы также отключим отображение осей и делений на графике.\n","    plt.axis('off')\n","    # Смотрим, что получилось\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"qG6fJOHZZwK5"},"source":["## Фильтр Байера\n","\n","Датчики изображения имеют фильтр Байера на сенсорных элементах (пикселях). Таким образом, каждый второй пиксель в четных строках красный, каждый второй пиксель в нечетных строках синий, и каждый второй пиксель во всех строках содержит зеленый:\n","\n","_ 0 1\n","\n","0 R G\n","\n","1 G B\n","\n","Давайте создадим необработанное изображение с таким шаблоном Байера из наших загруженных изображений. Мы можем использовать маски и срезы."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4pT9FiylaEva"},"outputs":[],"source":["#\n","print(image.shape)\n","red_mask = np.zeros(shape=image.shape[0:2],dtype=bool)\n","green_mask, blue_mask = red_mask.copy(), red_mask.copy()\n","red_mask[0::2,0::2] = True\n","blue_mask[1::2,1::2] = True\n","green_mask[0::2,1::2] = True\n","green_mask[1::2,0::2] = True\n","\n","# display red\n","rsize = np.ceil(np.asarray(red_mask.shape)/2.0).astype(int)\n","reds = image[:,:,2][red_mask].reshape(rsize)\n","#cv2_imshow(reds)\n","\n","# display blue\n","bsize = np.floor(np.asarray(blue_mask.shape)/2.0).astype(int)\n","blues = image[:,:,0][blue_mask].reshape(bsize)\n","#cv2_imshow(blues)\n","\n","# construct a Bayer image:\n","bayer = np.zeros(shape=(*image.shape[0:2],3),dtype=image.dtype)\n","# assing colors (BGR)\n","bayer[:,:,0][blue_mask]  = blues.flatten() # B\n","bayer[:,:,2][red_mask]   = reds.flatten() # R\n","bayer[:,:,1][green_mask] = image[:,:,1][green_mask] # Green\n","imshow(bayer[:16,:16]) # show zoomed in\n","cv2_imshow(bayer)"]},{"cell_type":"markdown","metadata":{"id":"1CuUgu3naTMb"},"source":["Первый рисунок  показывает, что регистрирует большинство цветных датчиков изображения. Процесс преобразования такого рисунка Байера в цветное изображение называется демозаикой (demosaicing)."]},{"cell_type":"markdown","metadata":{"id":"LGaewxNyak0c"},"source":["## Наивное изменение размера изображения\n","… просто отбрасывая строки и столбцы. Для этого мы можем использовать нотацию срезов Python."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"DwDCaej0aKvD"},"outputs":[],"source":["def downsample( img ):\n","    return img[0::2,0::2]\n","\n","half = downsample(image)    # 1/2 resolution\n","quad = downsample(half)     # 1/4\n","eighth = downsample(quad)   # 1/8\n","imshow(image)\n","#imshow(half)\n","#imshow(quad)\n","imshow(eighth)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GchqG6gPawCK"},"outputs":[],"source":["smooth = cv2.resize(image, eighth.shape[1::-1], interpolation=cv2.INTER_AREA)\n","imshow(smooth)"]},{"cell_type":"markdown","metadata":{"id":"SVYAd4Jxa-Dh"},"source":["Отбрасывание пикселей — не лучший способ уменьшения масштаба изображений.\n","\n","Давайте сравним с уменьшенным изображением с помощью встроенной функции изменения размера OpenCV."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ySrK-9-abEMj"},"outputs":[],"source":["smooth = cv2.resize(image, eighth.shape[1::-1], interpolation=cv2.INTER_AREA)\n","imshow(smooth)"]},{"cell_type":"markdown","metadata":{"id":"jHTDWaTpbaRz"},"source":["## Упражнения\n","\n","***1 упражнение.***\n","\n","Оттенки серого: Цвет хорош, но монохромные изображения также очень привлекательны. Отображение одного цветового канала выглядит не очень хорошо. Поэтому нам нужна взвешенная сумма всех каналов. Типичные веса для преобразования из RGB в оттенки серого:\n","\n","0,2989∗R+0,5870∗G+0,1140∗B\n","\n","(a) Загрузите изображение gogh.jpg. Преобразуйте его в оттенки серого и отобразите. Не забывайте, что каналы — это BGR.\n","\n","\n","***2 упражнение.***\n","\n","Гамма-кривая: 8-битные изображения хранятся нелинейно (как наше восприятие).\n","Обычной функцией, используемой для этого нелинейного линейного отображения, является гамма-кривая: $y=x^\\gamma$, где x — линейные значения в диапазоне [0,1]. Гамма равна $\\gamma=2.2$ в большинстве систем.\n","\n","(a) Линеаризуйте изображение и отобразите его. Обратите внимание, что отображение линейного изображения может выглядеть странно.\n","\n","(b) Примените разные γ (например, 0,5, 1,0 и 1,5) и посмотрите, что происходит."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8wyzMztKCJpG"},"outputs":[],"source":["# упражнение 1\n","image = cv2.imread(\"мальчик.jpg\")\n","B,G,R = image[:,:,0], image[:,:,1], image[:,:,2]\n","gray_image = np.round(0.2989*R+0.587*G+0.114*B)\n","gray_image = gray_image.astype('uint8')\n","imshow(gray_image)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Jh1RefSzCb0d"},"outputs":[],"source":["# упражнение 2\n","image = cv2.imread(\"мальчик.jpg\")\n","B,G,R = image[:,:,0], image[:,:,1], image[:,:,2]\n","gray_image = (0.2989*R+0.587*G+0.114*B)/255\n","gray_image = gray_image.astype('float32')\n","imshow(gray_image)\n","\n","gamma = 2.2\n","gray_image = gray_image**gamma\n","imshow(gray_image)\n","\n","for i in [0.5,1.0,1.5,2.0,2.1,2.2,2.5]:\n","  results = gray_image**i\n","  imshow(results)"]},{"cell_type":"markdown","metadata":{"id":"wy8Za7mx5uGn"},"source":["# Фильтры\n","\n","Пространственная фильтрация изображения – это метод, при котором каждая точка изображения последовательно обрабатывается с помощью оператора, представленного в виде квадратной матрицы. Результатом работы этого метода является оценка значимости каждого пикселя изображения. Одним из признаков значимости пикселей являются резкие перепады яркости.\n","\n","Большинство рассмотренных ниже методов основываются на одном из базовых свойств сигнала яркости – разрывности. Наиболее общим способом поиска разрывов является обработка изображения с помощью скользящей маски, называемой также фильтром, ядром, окном или шаблоном, которая представляет собой некую квадратную матрицу, соответствующую указанной группе пикселей исходного изображения. Элементы матрицы принято называть коэффициентами. Оперирование такой матрицей в каких-либо локальных преобразованиях называется фильтрацией или пространственной фильтрацией.\n","\n","Процесс основан на простом перемещении маски фильтра от точки к точке изображения; в каждой точке $(x,y)$ отклик фильтра вычисляется с использованием предварительно заданных связей. В случае линейной пространственной фильтрации отклик задается суммой произведения коэффициентов фильтра на соответствующие значения пикселей в области, покрытой маской фильтра.\n","\n","При обнаружении перепадов яркости используются дискретные аналоги производных первого и второго порядка."]},{"cell_type":"markdown","metadata":{"id":"bF1EcNJe5uGo"},"source":["### Фильтр Гаусса"]},{"cell_type":"markdown","metadata":{"id":"L7Q6ntVq5uGp"},"source":["Фильтр размытия по гауссу (широко известный ''gaussian blur'' в фотошопе)\n","достаточно часто применяется сам по себе или как часть других алгоритмов\n","обработки изображений.\n","\n","Применение размытия по Гауссу к изображению математически аналогично свёртке\n","изображения с помощью функции Гаусса. Оно также известно как двумерное\n","преобразование Вейерштрасса. Поскольку преобразование Фурье функции Гаусса само\n","является функцией Гаусса, применение размытия по Гауссу приводит к уменьшению\n","высокочастотных компонентов изображения. Таким образом, размытие по Гауссу\n","является фильтром нижних частот.\n","\n","\n","В этом способе размытия функция Гаусса (которая также используется для описания нормального распределения в теории вероятностей) используется для вычисления преобразования, применяемого к каждому пикселю изображения. Формула функции Гаусса в одном измерении:\n","\n","$${\\displaystyle G(x)={\\frac {1}{\\sqrt {2\\pi \\sigma ^{2}}}}e^{-{\\frac {x^{2}}{2\\sigma ^{2}}}}}$$\n","\n","В двух измерениях это произведение двух функций Гаусса, по одной для каждого измерения:\n","\n","$${\\displaystyle G(x,y)={\\frac {1}{2\\pi \\sigma ^{2}}}e^{-{\\frac\n","{x^{2}+y^{2}}{2\\sigma ^{2}}}}}$$\n","\n","где $x$, $y$ — координаты точки, а $\\sigma$ — среднеквадратическое отклонение нормального распределения. При применении в двух измерениях эта формула даёт поверхность, контуры которой представляют собой концентрические окружности с нормальным распределением относительно центральной точки."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"i_TH-hJe6Tsi"},"outputs":[],"source":["filename = \"мальчик.jpg\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yrpt_X7T5uGq"},"outputs":[],"source":["pic = PIL.Image.open(filename)\n","sigma = 10\n","pix = np.array(pic)\n","result = ndimage.gaussian_filter(pix, sigma)\n","PIL_image = PIL.Image.fromarray(np.uint8(result)).convert('L')\n","PIL_image.save(\"мальчик_Гаус.jpg\")\n","plt.imshow(pic)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4vTKM2U85uGr"},"outputs":[],"source":["plt.imshow(PIL_image)"]},{"cell_type":"markdown","metadata":{"id":"kYcTAq315uGs"},"source":["### Фильтр Робертса"]},{"cell_type":"markdown","metadata":{"id":"GQBP8F4W5uGs"},"source":["Перекрёстный оператор Робертса — один из ранних алгоритмов выделения границ, который вычисляет на плоском дискретном изображении сумму квадратов разниц между диагонально смежными пикселами. Это может быть выполнено сверткой изображения с двумя ядрами:\n","$$\\begin{bmatrix}+1\u00260\\\\0\u0026-1\\\\ \\end{bmatrix} \\text{ и } {\\begin{bmatrix}0\u0026+1\\\\-1\u00260\\\\ \\end{bmatrix}}$$\n","Иными словами, величина перепада G получаемого изображения вычисляется из исходных значений параметра Y в дискретных точках растра с координатами\n","$(x, y)$ по правилу: $${\\displaystyle G_{1}=Y_{x,y}-Y_{x+1,y+1}} \\text{ ; } {\\displaystyle G_{2}=Y_{x+1,y}-Y_{x,y+1}}$$\n","$${\\displaystyle G={\\sqrt {G_{1}^{2}+G_{2}^{2}}}}$$"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"r62pD7R_5uGs"},"outputs":[],"source":["roberts_cross_v = np.array([[1, 0 ],\n","                            [0,-1 ]])\n","roberts_cross_h = np.array([[ 0, 1 ],\n","                            [ -1, 0 ]])\n","#pix = cv2.imread(\"1.dicom.jpeg\", 0).astype('float64')\n","\n","\n","with PIL.Image.open(filename) as pix:\n","    pix.load()\n","\n","plt.imshow(pix)\n","b = pix.getbands()  # проверяем, сколько слоев в изображении\n","print(b)\n","\n","# преобразуем в серое\n","pix = pix.convert(\"L\")\n","\n","b = pix.getbands()  # проверяем, сколько слоев в изображении\n","print(b)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XeZkdhnc5uGt"},"outputs":[],"source":["vertical = ndimage.convolve(pix, roberts_cross_v)\n","horizontal = ndimage.convolve(pix, roberts_cross_h)\n","edged_img = np.sqrt( np.square(horizontal) + np.square(vertical))\n","\n","\n","PIL_image = PIL.Image.fromarray(np.uint8(edged_img))\n","\n","plt.imshow(PIL_image,cmap=plt.cm.gray)\n","PIL_image.save(\"мальчик_тест.jpg\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8_o6JIJ35uGt"},"source":["### Фильтр Прюитт"]},{"cell_type":"markdown","metadata":{"id":"k3ns7gGv5uGt"},"source":["Оператор Прюитт используется при обработке изображений, в частности в алгоритмах обнаружения границ. Технически это оператор дискретного дифференцирования, вычисляющий аппроксимацию градиента функции интенсивности изображения. В каждой точке изображения результатом оператора Превитта является либо соответствующий вектор градиента, либо норма этого вектора.\n","\n","Оператор использует два ядра 3×3, свёртывая исходное изображение для вычисления приближённых значений производных: одно по горизонтали и одно по вертикали. Положим $\\mathbf {A}$ исходным изображением, и ${\\displaystyle \\mathbf {G_{x}} }, {\\mathbf  {G_{y}}}$ — двумя изображениями, в которых каждая точка содержит горизонтальное и вертикальное приближение производной, которая рассчитывается как\n","\n","$$\\mathbf {G_{x}} = {\\begin{bmatrix}-1\u00260\u0026+1\\\\-1\u00260\u0026+1\\\\-1\u00260\u0026+1\\end{bmatrix}} * A$$\n","\n","$$\\mathbf {G_{y}} ={\\begin{bmatrix}-1\u0026-1\u0026-1\\\\0\u00260\u00260\\\\+1\u0026+1\u0026+1\\end{bmatrix}}*A$$"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fqSpbNMb5uGt"},"outputs":[],"source":["pic = PIL.Image.open(filename)\n","pix = np.array(pic)\n","input_shape = pix.shape\n","new_shape = input_shape[1], input_shape[0]\n","result = skimage.filters.prewitt(pix)\n","\n","# первоначальное изображение\n","plt.imshow(pic, cmap=plt.cm.gray, aspect='equal')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"j3t2__JK5uGt"},"outputs":[],"source":["fig = plt.figure(frameon=False)\n","ax = plt.Axes(fig, [0., 0., 1., 1.])\n","ax.set_axis_off()\n","fig.add_axes(ax)\n","\n","#измененное изображение\n","plt.imshow(result, cmap=plt.cm.gray, aspect='equal')\n","\n","\n","plt.savefig(\"мальчик_тест2.jpg\", dpi=300)"]},{"cell_type":"markdown","metadata":{"id":"xr4SFgQk5uGu"},"source":["### Фильтр Собеля"]},{"cell_type":"markdown","metadata":{"id":"_o9mGyTW5uGu"},"source":["Оператор Собеля — дискретный дифференциальный оператор, вычисляющий приближённое значение градиента яркости изображения.\n","\n","Строго говоря, оператор использует ядра $3 \\times 3$, с которыми сворачивают исходное изображение для вычисления приближённых значений производных по горизонтали и по вертикали. Пусть ${\\displaystyle \\mathbf {A} }$ — это исходное изображение, а ${\\displaystyle \\mathbf {G} _{x}}$ и ${\\displaystyle \\mathbf {G} _{y}}$ — два изображения, на которых каждая точка содержит приближённые производные по ${\\displaystyle x}$ и по\n","${\\displaystyle y}$. Они вычисляются следующим образом: $$\\mathbf {G} _{y} = {\\begin{bmatrix}+1\u0026+2\u0026+1\\\\0\u00260\u00260\\\\-1\u0026-2\u0026-1\\\\\\end{bmatrix}}*\\mathbf {A}$$ и $$\\mathbf {G} _{x}={\\begin{bmatrix}-1\u00260\u0026+1\\\\-2\u00260\u0026+2\\\\-1\u00260\u0026+1\\end{bmatrix}}*\\mathbf {A}$$\n","\n","$*$ - двумерная операция свертки.\n","\n","Координата ${\\displaystyle x}$ здесь возрастает «направо», а ${\\displaystyle y}$ — «вниз». В каждой точке изображения приближённое значение величины градиента можно вычислить путём использования полученных приближенных значений производных: ${\\mathbf  {G}}={\\sqrt  {{{\\mathbf  {G}}_{x}}^{2}+{{\\mathbf  {G}}_{y}}^{2}}}$ (имеется в виду поэлементно).\n","Используя эту информацию, мы можем вычислить искомое направление градиента: ${\\mathbf  {\\Theta }}=\\operatorname {arctan}\\left({{\\mathbf  {G}}_{y} \\over {\\mathbf  {G}}_{x}}\\right)$,"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IC13wYtr5uGu"},"outputs":[],"source":["pic = PIL.Image.open(filename)\n","pix = np.array(pic)\n","input_shape = pix.shape\n","new_shape = input_shape[1], input_shape[0]\n","result = skimage.filters.sobel(pix)\n","fig = plt.figure(frameon=False)\n","ax = plt.Axes(fig, [0., 0., 1., 1.])\n","ax.set_axis_off()\n","fig.add_axes(ax)\n","plt.imshow(result, cmap=plt.cm.gray, aspect='equal', interpolation=\"mitchell\")\n","plt.savefig(\"мальчик_Собеля.jpg\", dpi=300)"]},{"cell_type":"markdown","metadata":{"id":"rHKpgbq45uGv"},"source":["### Фильтр Лапласа"]},{"cell_type":"markdown","metadata":{"id":"qVfWa-d65uGv"},"source":["Фильтр Лапласа это очередной фильтр, основанный на принципе нахождения\n","производных и учитывающий резкие изменения яркости относительно соседних\n","пикселей.\n","\n","Однако то, что отличает его от других фильтров, используемых при обработке\n","изображений для обнаружения границ и выделения признаков, это то, что фильтр\n","Лапласа \"--- это фильтр второго порядка. Когда мы используем производные фильтры\n","первого порядка, мы должны применять отдельные фильтры для обнаружения\n","вертикальных и горизонтальных краев (как это было с Прюитт, Собелем и т.д.), а\n","затем объединять их. Но фильтр Лапласа обнаруживает все края независимо от\n","направлений.\n","\n","Математически, фильтр Лапласа определяется как:\n","\n","$$\\Delta^2 f = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2}$$\n","\n","Всего существует два вида фильтров Лапласа: положительный и отрицательный.\n","\n","Положительный оператор Лапласа использует маску, в которой центральный элемент имеет отрицательное значение, а угловые элементы — 0. Этот фильтр идентифицирует внешние края изображения. Пример маски фильтра приведен ниже.\n","\n","${\\begin{bmatrix}0\u00261\u00260\\\\1\u0026-4\u00261\\\\0\u00261\u00260\\\\\\end{bmatrix}}$\n","\n","Отрицательный оператор Лапласа используется для поиска внутренних краев изображения. Он использует стандартную маску, в которой центральный элемент имеет положительное значение, углы - $0$, а все остальные элементы - $-1$. Пример приведен ниже.\n","\n","${\\begin{bmatrix}0\u0026-1\u00260\\\\-1\u00264\u0026-1\\\\0\u0026-1\u00260\\\\\\end{bmatrix}}$\n","\n","В обоих случаях сумма значений в фильтре должна быть равна $0$, при этом далеко\n","необязательно применять конкретные два примера: можно попробовать другие\n","варианты этих масок."]},{"cell_type":"markdown","metadata":{"id":"FjoiXeAb5uGv"},"source":["Пересечение нуля (англ. Zero crossing) — это точка, в которой на графике функции\n","меняется знак математической функции. При обработке изображений обнаружение края\n","с использованием фильтра Лапласа происходит путем маркировки точек, которые\n","приводят к нулю на графике, как потенциальных точек края. Этот метод хорошо\n","работает на изображениях для поиска краев в обоих направлениях, но плохо\n","работает, когда на изображении обнаружены шумы. Поэтому обычно изображение\n","сглаживается, применяя фильтр Гуасса перед фильтром Лапласа. Его часто называют\n","фильтром Лапласа-Гуасса (LoG).\n","\n","Мы можем объединить операторы Гаусса и Лапласа вместе, и математическое представление комбинированного фильтра будет следующим:\n","\n","$$LoG(x, y) = -\\frac{1}{\\pi \\sigma^4} [1 - \\frac{x^2 + y^2}{2\\sigma^2}] e^{-\\frac{x^2 + y^2}{2\\sigma^2}}$$"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2jD_5eHa5uGv"},"outputs":[],"source":["def LoG_filter(image, sigma, size=None):\n","    # ядро LoG\n","    if size is None:\n","        size = int(6 * sigma + 1) if sigma \u003e= 1 else 7\n","\n","    if size % 2 == 0:\n","        size += 1\n","\n","    x, y = np.meshgrid(np.arange(-size//2+1, size//2+1), np.arange(- size // 2 + 1, size // 2 + 1))\n","    kernel = -(1/(np.pi * sigma**4)) * (1 - ((x**2 + y**2) / (2 * sigma**2))) * np.exp(- (x**2 + y**2) / (2 * sigma**2))\n","    kernel = kernel / np.sum(np.abs(kernel))\n","\n","    result = ndimage.convolve(image, kernel)\n","    return result\n","\n","image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n","sigma = 2.0\n","filtered_image = LoG_filter(image, sigma)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JjmQOE165uGv"},"outputs":[],"source":["fig = plt.figure(frameon=False)\n","ax = plt.Axes(fig, [0., 0., 1., 1.])\n","ax.set_axis_off()\n","fig.add_axes(ax)\n","plt.imshow(filtered_image, cmap=plt.cm.gray, aspect='auto')\n","plt.savefig(\"мальчик_Лапласа.jpg\", dpi=300)"]},{"cell_type":"markdown","metadata":{"id":"Dl35AxSQ5uGw"},"source":["## Выделение областей"]},{"cell_type":"markdown","metadata":{"id":"ZgzUnsrx5uGw"},"source":["### MeanShift"]},{"cell_type":"markdown","metadata":{"id":"ihhclZMU5uGw"},"source":["MeanShift - алгоритм кластеризации на основе центроид, который работает путем\n","обновления кандидатов на центроиды, чтобы они были средними точками в заданной\n","области. Затем эти кандидаты фильтруются на этапе постобработки, чтобы исключить\n","почти дубликаты и сформировать окончательный набор центроид.\n","\n","Сдвиг среднего значения (англ. MeanShift) является процедурой для определения\n","местоположения максимумов (мод) плотности вероятности, задаваемой дискретной\n","выборкой по этой функции. Метод является итеративным, и мы начинаем с начальной\n","оценки $x$.\n","\n","Пусть будет задана ядерная функция ${\\displaystyle K(x_{i}-x)}$. Эта функция\n","определяет вес ближайших точек для переоценки среднего. Обычно используется\n","гауссово ядро от расстояния до текущей оценки ${\\displaystyle\n","K(x_{i}-x)=e^{-c||x_{i}-x||^{2}}}$. Взвешенное среднее плотности в окне,\n","определённом функцией $K$ равно $${\\displaystyle m(x)={\\frac {\\sum _{x_{i}\\in\n","N(x)}K(x_{i}-x)x_{i}}{\\sum _{x_{i}\\in N(x)}K(x_{i}-x)}}}$$ где $N(x)$ является\n","окрестностью точки $x$, то есть набором точек, для которых ${\\displaystyle\n","K(x_{i})\\neq 0}$."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5epjQW2Q5uGw"},"outputs":[],"source":["from sklearn.cluster import MeanShift, estimate_bandwidth"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"H1-Dd9aT5uGw"},"outputs":[],"source":["image = PIL.Image.open(filename).convert('RGB')\n","\n","plt.imshow(image, cmap=plt.cm.gray, aspect='equal')\n","\n","\n","img = np.array(image)\n","shape = img.shape\n","new_shape = shape[1], shape[0]\n","reshaped_image = np.reshape(image, [-1, 3])\n","bandwidth = estimate_bandwidth(reshaped_image, quantile=0.1, n_samples=300)\n","\n","msc = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n","msc.fit(reshaped_image)\n","\n","labels = msc.labels_\n","result_image = np.reshape(labels, shape[:2])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Usr5mpL55uGw"},"outputs":[],"source":["fig = plt.figure(frameon=False)\n","ax = plt.Axes(fig, [0., 0., 1., 1.])\n","ax.set_axis_off()\n","fig.add_axes(ax)\n","\n","plt.imshow(result_image, cmap=plt.cm.gray, aspect='equal')\n","plt.savefig(\"мальчик_MeanShift.jpg\", dpi=300)"]},{"cell_type":"markdown","metadata":{"id":"NZybE3KO5uGw"},"source":["### Floodfill"]},{"cell_type":"markdown","metadata":{"id":"QzMBFrgU5uGx"},"source":["Алгоритм заполнения позволяет выбирать наборы точек, однородные по цвету. Для\n","этого необходимо выбрать исходный пиксель и задать интервал изменения цвета\n","соседних пикселей относительно исходного (определенное пороговое значение\n","разницы между яркостью соседнего и исходного пикселей, меньше которого соседний\n","пиксель окрашивается в цвет исходного)."]},{"cell_type":"markdown","metadata":{"id":"DfI6f39y5uGx"},"source":["img: изображение, которое нужно залить\n","\n","mask: mask layer. Используйте маску, чтобы указать область, в которой используется алгоритм. Если он используется для полного изображения, размер маскирующего слоя равен числу строк в исходном изображении + 2 и количеству столбцов + 2.\n","Размер матрицы 0, край окружности будет установлен в 1 при использовании алгоритма. Только положение, соответствующее 0 на слое маски, может быть залито, поэтому слой маски инициализируется в матрицу 0. [dtype:np.uint8】\n","\n","seed: это начальная точка алгоритма затопления, которая также основана на оценке пикселей этой точки, чтобы определить, затоплены ли пиксельные точки с похожими цветами.\n","\n","newvalue: это новое присвоенное значение (B, G, R) для затопленной области\n","\n","(loDiff1, loDiff2, loDiff3): это значение пикселя, которое можно уменьшить относительно пикселя начальной точки, то есть начального значения (B0, G0, R0), а нижняя граница области затопления равна (B0-loDiff1, G0-loDiff2, R0-loDiff3)\n","\n","(upDiff1, upDiff2, upDiff3): это значение пикселя, которое может быть направлено вверх относительно начальной точки, то есть начальное значение (B0, G0, R0), верхний предел области затопления равно (B0 + upDiff1, G0 + upDiff2, R0 + upDiff3 )\n","\n","флаг: режим обработки алгоритма затопления."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CGyM7QVH5uGx"},"outputs":[],"source":["img = cv2.imread(filename)\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","copyimg = img.copy()\n","h, w = copyimg.shape[:2]\n","mask = np.zeros([h + 2, w + 2], np.uint8)\n","\n","# нужно задать координаты точек - центров заливки. Без этого работать не будет!\n","\n","cv2.floodFill(copyimg, mask, (165,60), (0, 255, 255), (50, 20, 50), (50, 50 ,30), cv2.FLOODFILL_FIXED_RANGE)\n","\n","fig = plt.figure(frameon=False)\n","ax = plt.Axes(fig, [0., 0., 1., 1.])\n","ax.set_axis_off()\n","fig.add_axes(ax)\n","plt.imshow(copyimg)\n","plt.savefig(\"мальчик_Floodfill.jpg\", dpi=300)"]},{"cell_type":"markdown","metadata":{"id":"yAyByTVc5uGx"},"source":["Однако далеко не всегда удается удачно подобрать исходные для заливки пиксели.\n","Поэтому, чтобы не заниматься выбором исходного пикселя, достаточно применять\n","преобразование изображения с помощью метода cv2.threshold"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8CmQrbOD5uGx"},"outputs":[],"source":["image = cv2.imread(filename)\n","gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","lower_bound = 50\n","upper_bound = 50\n","\n","(thresh, BnW_image) = cv2.threshold(gray_image, lower_bound, upper_bound, cv2.THRESH_BINARY)\n","im = PIL.Image.fromarray(BnW_image)\n","im.save(\"мальчик_Floodfill2.jpg\")\n","plt.imshow(im)"]},{"cell_type":"markdown","metadata":{"id":"zyeESvlF5uGy"},"source":["## Зашумление и удаление шумов"]},{"cell_type":"markdown","metadata":{"id":"6Lcj3UHe5uGy"},"source":["Лучший способ добавить шум к данным — это случайно изменить значения точек\n","данных. Можно выбрать некоторые точки данных в случайных местах и изменить их\n","значения на случайную величину. При этом можно контролировать количество точек\n","данных, которые нужно изменить, и степень изменения. Добавление шума к данным и\n","контроль над ним могут быть достигнуты с помощью нескольких методов добавления\n","шума:\n","\n","1. Гауссов шум\n","2. Импульсный шум.\n","3. Шум соли и перца\n","4. Шум квантования\n"]},{"cell_type":"markdown","metadata":{"id":"Ai7l_4DP5uGy"},"source":["### Гауссов шум"]},{"cell_type":"markdown","metadata":{"id":"UWXkvGaO5uGz"},"source":["Гауссов шум это по сути просто (опять) распределение Гаусса. Когда он\n","добавляется к данным, его называют шумом, вызывая искажение данных. Этот шум\n","широко используется по следующим причинам:\n","\n","1. Он имеет хорошо изученные свойства и полностью определяется своим средним\n","   значением и стандартным отклонением, поэтому над ним можно добиться хорошего\n","   контроля и предсказуемости.\n","\n","2. Большинство шумов, встречающихся в природе, напоминают гауссов шум, что\n","делает его идеальным выбором для моделирования.\n","\n","3. Простота формирования"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZQ_MXrXe5uGz"},"outputs":[],"source":["# здесь представлен пример формирования шума на сером изображении, пример на\n","# цветном будет ниже\n","\n","img = cv2.imread('мальчик.jpg')\n","img_gray = img[:,:,1]\n","noise = np.random.normal(0, 50, img_gray.shape)\n","img_noised = img_gray + noise\n","img_noised = np.clip(img_noised, 0, 255).astype(np.uint8)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_n7zR8WS5uG0"},"outputs":[],"source":["fig = plt.figure(frameon=False)\n","ax = plt.Axes(fig, [0., 0., 1., 1.])\n","ax.set_axis_off()\n","fig.add_axes(ax)\n","plt.imshow(img_noised, cmap=plt.cm.gray, aspect='auto')\n","plt.savefig(\"мальчик_Гауссов.jpg\", dpi=300)"]},{"cell_type":"markdown","metadata":{"id":"GkEyxJU05uG0"},"source":["### Импульсный шум"]},{"cell_type":"markdown","metadata":{"id":"CZVm-zeI5uG0"},"source":["Импульсный шум — это, по сути, внезапное увеличение или уменьшение значений\n","данных. Добавление такого шума может имитировать реальные данные, которые обычно имеют несколько всплесков в случайных местах. Эти пики также называют выбросами. Вы можете добавить импульсный шум, просто увеличивая или уменьшая значения данных в нескольких случайных местах данных."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0xOyha7-5uG0"},"outputs":[],"source":["x = np.arange(0, 360, 1)\n","y = np.sin(np.deg2rad(x))\n","\n","noise_sample = np.random.default_rng().uniform(0.2*min(y), 0.3*max(y), int(0.03*len(y)))\n","zeros = np.zeros(len(y) - len(noise_sample))\n","noise = np.concatenate([noise_sample, zeros])\n","np.random.shuffle(noise)\n","y_noised = y + noise"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zUxjejLE5uG0"},"outputs":[],"source":["image = cv2.imread(filename)\n","\n","h, w = image.shape[:2]\n","\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","s = 300  # количество точек - шума\n","\n","noise_sample = np.random.default_rng().uniform(low=200, high=250, size=s)\n","\n","rs1 = np.random.randint(0,gray.size/h-1,s)\n","rs2 = np.random.randint(0,gray.size/w-1,s)\n","\n","j = 0\n","\n","# добавляем шум\n","for i in noise_sample:\n","    gray[rs2[j]][rs1[j]] += i\n","    j += 1\n","\n","plt.imshow(gray, cmap=plt.cm.gray, aspect='equal')"]},{"cell_type":"markdown","metadata":{"id":"Ia4_WLkG5uG1"},"source":["### Шум соли и перца (Salt-and-Pepper)"]},{"cell_type":"markdown","metadata":{"id":"Wg0QsvUD5uG1"},"source":["Шум соли и перца — это тип импульсного шума, в котором случайные точки\n","данных заменяются минимальными или максимальными значениями данных. Этот тип\n","шума естественным образом возникает в данных изображения, вызванный\n","неисправностями датчика или повреждением данных во время хранения или передачи\n","данных, и, таким образом, этот шум может имитировать отсутствующую или\n","поврежденную информацию."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dZxebw7x5uG1"},"outputs":[],"source":["img_size = img_gray.size\n","noise_percentage = 0.1\n","noise_size = int(noise_percentage*img_size)\n","\n","random_indices = np.random.choice(img_size, noise_size)\n","img_noised = img_gray.copy()\n","noise = np.random.choice([img_gray.min(), img_gray.max()], noise_size)\n","img_noised.flat[random_indices] = noise"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5xgNlNEk5uG1"},"outputs":[],"source":["fig = plt.figure(frameon=False)\n","ax = plt.Axes(fig, [0., 0., 1., 1.])\n","ax.set_axis_off()\n","fig.add_axes(ax)\n","plt.imshow(img_noised, cmap=plt.cm.gray, aspect='auto')\n","plt.savefig(\"мальчик_соль.jpg\", dpi=300)"]},{"cell_type":"markdown","metadata":{"id":"gDaLNn8Y5uG2"},"source":["### Шум квантования"]},{"cell_type":"markdown","metadata":{"id":"RX3NmW9c5uG2"},"source":["Это тип шума, при котором некоторые случайные значения непрерывной переменной представлены дискретными значениями, что приводит к снижению точности этих значений.\n","\n","Например, рассмотрим следующий набор данных, содержащий непрерывные значения:\n","\n","$[1.22, 4.35, 6.30, 8.01, 10.44…]$\n","\n","Когда к этим данным добавляется шум квантования, некоторые из его значений\n","станут дискретными.\n","\n","$[1.22, \\textit{4}, 6.30, 8.01, \\textit{10}, \\dots]$\n","\n","Эти дискретизированные значения представляют собой шум. Один из самых простых\n","способов добавить этот шум к вашим данным — просто округлить некоторые случайные значения в данных."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"AocjEmzG5uG2"},"outputs":[],"source":["# Генерация исходного сигнала-примера\n","x = np.arange(0, 100, 2)\n","y = 0.3 * x + 0.6\n","\n","# Генерация шума\n","y_size = len(y)\n","noise_percentage = 0.2\n","noise_size = int(noise_percentage * y_size)\n","random_indices = np.random.choice(y_size, noise_size)\n","y_noised = y.copy()\n","y_noised[random_indices] = np.rint(y_noised[random_indices])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"U_6CY82V5uG2"},"outputs":[],"source":["plt.subplot(121)\n","plt.plot(y)\n","plt.xlabel(\"Исходный сигнал\")\n","plt.subplot(122)\n","plt.plot(y_noised)\n","plt.xlabel(\"Зашумленный сигнал\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"IbUXTWMp5uG3"},"source":["### Удаление шума из изображения и видео"]},{"cell_type":"markdown","metadata":{"id":"vwIi9VHA5uG3"},"source":["Существует множество методов сглаживания изображений, таких как размытие по\n","Гауссу, медианное размытие и т. д. Их иногда принято использовать для удаления\n","небольшого количества шума. В них берется небольшая окрестность вокруг\n","зашумленного пикселя и выполняется особая операция (средневзвешенное по Гауссу,\n","медиана значений и т. д.), чтобы заменить центральный элемент. Таким образом,\n","удаление шума в пикселе происходит в этих алгоритмах локально по отношению к его\n","окрестностям.\n","\n","Также можно использовать параметры шума. Рассмотрим зашумленный пиксель, $p =\n","p_0 + n$, где $p_0$ — истинное значение пикселя, а $n$ — шум в этом пикселе.\n","Можно взять большое количество одинаковых пикселей (скажем, $N$) из разных\n","изображений и вычислить их среднее значение. Тогда в идеале можно получить $p = p_0$,\n","поскольку среднее значение шума равно нулю."]},{"cell_type":"markdown","metadata":{"id":"qYppjO6s5uG3"},"source":["Библиотека OpenCV обладает четырьмя функциями удаления шума:\n","\n","* cv.fastNlMeansDenoising() - работает с изображениями в градациях серого\n","* cv.fastNlMeansDenoisingColored() - работает с цветными изображениями\n","* cv.fastNlMeansDenoisingMulti() - работает с рядом изображений, полученных за небольшой промежуток времени\n","* cv.fastNlMeansDenoisingColoredMulti() - то же, что выше, только для цветных изображений"]},{"cell_type":"markdown","metadata":{"id":"RZgLAG4g5uG3"},"source":["#### cv.fastNlMeansDenoising()"]},{"cell_type":"markdown","metadata":{"id":"vTLyVgeq5uG4"},"source":["Аргументы:\n","\n","* h: параметр, определяющий силу фильтра. Более высокое значение h лучше удаляет шум, но также удаляет больше деталей изображения.\n","* hForColorComponents: то же, что и h, но только для цветных изображений"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HiCcxnWt5uG4"},"outputs":[],"source":["img = cv2.imread('мальчик_Гауссов.jpg')\n","dst = cv2.fastNlMeansDenoisingColored(img, None, 25)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"he28r_6e5uG4"},"outputs":[],"source":["plt.figure(figsize=(14, 10), dpi=80)\n","plt.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SWiWoQoD5uG4"},"outputs":[],"source":["plt.figure(figsize=(14, 10), dpi=80)\n","plt.imshow(dst)"]},{"cell_type":"markdown","metadata":{"id":"ly0DXM0h5uG5"},"source":["#### cv.fastNlMeansDenoisingColored()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"UVnik-Vs5uG5"},"outputs":[],"source":["# добавляем шумы и сохраняем\n","\n","img = cv2.imread(\"медведь.jpg\")[...,::-1] / 255.0\n","noise = np.random.normal(loc=0, scale=1, size=img.shape)\n","noisy = np.clip((img + noise * 0.2), 0,1)\n","noisy2 = np.clip((img + noise * 0.4), 0,1)\n","\n","plt.figure(figsize=(12, 12))\n","fig = plt.figure(frameon=False)\n","ax = plt.Axes(fig, [0., 0., 1., 1.])\n","ax.set_axis_off()\n","fig.add_axes(ax)\n","plt.imshow(noisy2, aspect='auto')\n","plt.savefig(\"noised_kisa.jpg\", dpi=300)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Vg4O9LeZ5uG5"},"outputs":[],"source":["img = cv2.imread('noised_kisa.jpg')\n","dst = cv2.fastNlMeansDenoisingColored(img, None, 15, 10, 7, 21)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WRAZcveY5uG6"},"outputs":[],"source":["plt.figure(figsize=(12, 12))\n","fig = plt.figure(frameon=False)\n","ax = plt.Axes(fig, [0., 0., 1., 1.])\n","ax.set_axis_off()\n","fig.add_axes(ax)\n","plt.imshow(dst[...,::-1] / 255.0, aspect='auto')\n","plt.savefig(\"denoised_kisa.jpg\", dpi=300)"]},{"cell_type":"markdown","metadata":{"id":"fC0SJIgO5uG6"},"source":["#### cv.fastNlMeansDenoisingColoredMulti()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"S76KvAOh5uG6"},"outputs":[],"source":["cap = cv2.VideoCapture('/content/drive/MyDrive/data/fit_cv/filters/kisa.mp4')\n","img = [cap.read()[1] for i in range(5)]\n","\n","gray = [cv2.cvtColor(i, cv2.COLOR_BGR2GRAY) for i in img]\n","gray = [np.float64(i) for i in gray]\n","\n","noise = np.random.randn(*gray[1].shape) * 25\n","noisy = [i + noise for i in gray]\n","noisy = [np.uint8(np.clip(i, 0, 255)) for i in noisy]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5a6Aqkkf5uG6"},"outputs":[],"source":["dst = cv2.fastNlMeansDenoisingMulti(noisy, 2, 5, None, 20, 7, 35)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GpjbvOJb5uG7"},"outputs":[],"source":["# исходный кадр, зашумленный, с удаленным шумом\n","plt.figure(figsize=(20, 20))\n","plt.subplot(131), plt.imshow(gray[2],'gray')\n","plt.subplot(132), plt.imshow(noisy[2],'gray')\n","plt.subplot(133), plt.imshow(dst,'gray')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"TYSLE4FtGpAe"},"source":["#Лабараторная работа 1\n","Найдём три фильтра для свёртки изображения"]},{"cell_type":"markdown","metadata":{"id":"e5YidV7cIgQm"},"source":["Фильтр 1. Выделение краёв Кэнни -  используется для определения границ объектов на изображении."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"QByPK2uLGoMp"},"outputs":[],"source":["image_boy = cv2.imread(\"мальчик.jpg\")\n","image_boy_1 = cv2.Canny(image, 100, 200)\n","cv2_imshow(image_boy_1)"]},{"cell_type":"markdown","metadata":{"id":"96swO4S2KIAD"},"source":["Фильтр 2. Аффинное преобразование — это преобразование изображения, сохраняющее прямые линии и параллельность (но не углы и длины). Фактически, это любые комбинации базовых операций:\n","Поворот (rotation),Масштабирование (scaling),Сдвиг (translation) + Наклон (shear)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"FA32Bt-oJM3S"},"outputs":[],"source":["\n","rows, cols = image_boy.shape[:2]\n","M = cv2.getRotationMatrix2D((cols/2, rows/2), 45, 1)  # Поворот на 45°\n","rotated = cv2.warpAffine(image_boy, M, (cols, rows))\n","cv2_imshow(rotated)"]},{"cell_type":"markdown","metadata":{"id":"AaYcwy3HL462"},"source":["Фильтр 3. Мультяшный эффект - Превращает фото в изображение, похожее на мультфильм или комикс: гладкие цветовые области + чёткие контуры."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"oaSmGM8wKz0L"},"outputs":[],"source":["def cartoon_effect(image_boy):\n","    # 1. Уменьшаем шум\n","    img_color = cv2.bilateralFilter(image_boy, 9, 300, 300)\n","\n","    # 2. Создаём контуры\n","    gray = cv2.cvtColor(image_boy, cv2.COLOR_BGR2GRAY)\n","    gray_blur = cv2.medianBlur(gray, 7)\n","    edges = cv2.adaptiveThreshold(gray_blur, 255,\n","                                 cv2.ADAPTIVE_THRESH_MEAN_C,\n","                                 cv2.THRESH_BINARY, 9, 2)\n","\n","    # 3. Накладываем\n","    edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n","    cartoon = cv2.bitwise_and(img_color, edges_colored)\n","    return cartoon\n","a = image_boy\n","cv2_imshow(cartoon_effect(a))"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}